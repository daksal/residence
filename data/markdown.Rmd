---
title: "야놀자 & 여기어때"
output:
  html_document: default
  pdf_document: default
date: "2022-10-19"
---

> -   기간: 2020.02.01 \~ 2022.10.19
>
> 빅카인즈 키워드 검색을 통해 '야놀자'와 '여기어때' 기업에 대한 기사를 분석함
>
> 분석 기간은 2020년 02월(코로나 발생 시점)부터 2022년 10월까지의 기사를 다루었다.
>
> 야놀자는 3620건, 여기어때는 609건의 기사를 분석했다.
>
> 분석 순서로는 **총빈도, 상대빈도, 감정어 분석, 주제모형** 순으로 분석했다.

------------------------------------------------------------------------

------------------------------------------------------------------------

### 1. 분석에 앞선 기본적인 준비

##### *1) 패키지 설치 및 불러오기*

<details>

<summary>패키지 불러오기</summary>

::: {markdown="1-1"}
```{r 패키지 불러오기, include=FALSE, warning=FALSE}

c( "rio", "psych", "psychTools", "skimr", "janitor", 
   
   "tidyverse", "tidytable", "tidymodels", "lm.beta",
   
   "GGally", "ggforce", "gt", "mdthemes", "patchwork",
   
   "r2symbols", "equatiomatic", "purrr", "palmerpenguins",
   
   "textdata", "tidytext", "epubr", "stm", "quarto", "wordcloud",
   
   "RcppMeCab", "KoNLP", "tidyr", "dplyr", "tidylo", "lubridate"
   
) -> pkg 

lapply(pkg, require, ch = T)

sapply(pkg, function(x){

  if(!require(x, ch = T)) install.packages(x)

  library(x, ch = T)

})
```
:::

</details>

##### *2) 파일 경로 설정*

<details>

<summary>파일경로 설정</summary>

```{r}
#| label: 파일경로 설정
#| include: true
#| warning: false

setwd("C:/Users/YH JUNG/Documents/R/GIT/residence/data")

getwd()
```

</details>

##### *3) 감정어 사전 설치 및 불러오기*

<details>

<summary>감정어 사전 설치 및 불러오기</summary>

```{r}
#| label: 감정어 사전 다운 및 설치
#| include: false
#| warning: false

url_v <- "https://github.com/park1200656/KnuSentiLex/archive/refs/heads/master.zip"

dest_v <- "data/knusenti.zip"

download.file(url = url_v, destfile = dest_v, mode = "wb")

list.files("data/KnuSentiLex-master/")
```

</details>

##### *4) 자료 불러오기 및 자료 정제*

<details>

<summary>빅카인즈 야놀자 & 여기어때 자료</summary>

```{r}
#| label: 빅카인즈 야놀자 & 여기어때 자료
#| include: true
#| warning: false

# 야놀자
yanolja_df <- readxl::read_excel("C:/Users/YH JUNG/Documents/R/GIT/residence/data/yanolja_main_data(2020.02 ~ 2022.10).xlsx") %>%
  
select.(제목, 언론사, 본문, URL)

yanolja_tk <- yanolja_df %>%
  
drop_na() %>%
  
unnest_tokens(word, 제목, token = pos) %>%
  
separate(word, c("word", "pos"), sep = "/") %>%
  
filter(pos == 'nng')

#여기어때
hah_df <- readxl::read_excel("C:/Users/YH JUNG/Documents/R/GIT/residence/data/hah_main_data(2020.02 ~ 2022.10).xlsx") %>%
  
select.(제목, 언론사, 본문, URL)

hah_tk <- hah_df %>%
  
drop_na() %>%
  
unnest_tokens(word, 제목, token = pos) %>%
  
separate(word, c("word", "pos"), sep = "/") %>%
  
filter(pos == 'nng')
```

</details>

------------------------------------------------------------------------

------------------------------------------------------------------------

### 2. 총빈도 & 상대빈도

#### 1) 총빈도

<details>

<summary>야놀자 총빈도</summary>

```{r}
#| label: 야놀자 총빈도
#| include: true
#| warning: false

yanolja_total <- yanolja_tk %>%

count(word, sort = T) %>%

slice_max(n, n = 15) %>%

ggplot(aes(x = n,

y = reorder(word, n))) +

geom_col(show.legend = F)

yanolja_total
```

</details>

야놀자의 총빈도를 확인한 결과 주로 2가지 주제를 살펴볼 수 있었다.

경제와 여행이다.

기사를 통해 확인한 결과 야놀자는 인터파크에 인수되며 투자자의 관심이 쏟아졌고 유니콘 기업이다보니 관련 키워드가 많이 보였다.

<details>

<summary>여기어때 총빈도</summary>

```{r}
#| label: 여기어때 총빈도
#| include: true
#| warning: false

hah_total <- hah_tk %>%

count(word, sort = T) %>%

slice_max(n, n = 15) %>%

ggplot(aes(x = n,

y = reorder(word, n))) +

geom_col(show.legend = F)

hah_total
```

</details>

여기어때는 여행과 관련된 키워드가 가장 많이 보여졌다.

플랫폼에 대한 이야기도 함께 등장하는 것을 확인할 수 있다.

#### 2) 상대빈도

<details>

<summary>상대빈도</summary>

```{r}
#| label: 상대빈도
#| include: true
#| warning: false

yanolja_df %>% 
  unnest_tokens(output = word, input = 본문, token  = pos) %>% 
  separate(col = word, 
           into = c("word", "pos"),
           sep = "/") %>% 
  filter(pos == "nng")-> yj_df

hah_df %>% 
  unnest_tokens(output = word, input = 본문, token  = pos) %>% 
  separate(col = word, 
           into = c("word", "pos"),
           sep = "/") %>% 
  filter(pos == "nng") -> hh_df

#상대빈도 결합
bind_rows(yj_df, hh_df, .id = "기업")  %>% 
  filter(str_length(word) > 1) %>%
  filter(word != "여기") %>% 
  filter(word != "어때") %>% 
  filter(word != "야놀자") %>% 
  count(word, 기업) %>% 
  bind_log_odds(set = 기업,
                feature = word, 
                n = n) %>% 
  arrange(-log_odds_weighted) -> weighted_log_odds_df

weighted_log_odds_df %>%
  group_by(기업 = ifelse(기업 > 1, "여기어때", "야놀자")) %>%
  slice_max(abs(log_odds_weighted), n = 15) %>%
  ggplot(aes(x = log_odds_weighted,
             y = reorder(word, log_odds_weighted),
             fill = 기업)) +
  geom_col(show.legend = F) +
  facet_wrap(~기업, scale = "free")
```

</details>

상대빈도를 통해서는 야놀자가 가지고 있는 자체적인 블록체인 시스템에 대한 단어가 여기어때에 비해 많이 나왔으며

기업적 측면에서 살펴보았을 때에도 야놀자는 증시, 지수, 종목, 매도와 같은 주식과 관련된 단어가 많이 사용되었음을 확인할 수 있다.

반면에, 여기어때는 여행과 숙박, 액티비티와 같이 여행 테마의 주제가 많이 나타났다.

이노베이션이라는 단어도 많이 사용된 것을 확인할 수 있는데 여기어때를 운영하는 위드이노베이션이 자신의 기업 이름을 여기어때 컴퍼니로 변경했다는 내용을 기사를 통해 확인할 수 있었다.

------------------------------------------------------------------------

### 3. 감정분석

##### 1) 사전 내용 선택

<details>

<summary>사전 내용 선택</summary>

```{r}
#| label: 사전 내용 선택
#| include: false
#| warning: false

senti_name_v <- list.files("data/KnuSentiLex-master/.")[9]

senti_dic_df <- read_tsv("data/KnuSentiLex-master/SentiWord_Dict.txt", col_names = F)

```

</details>

##### 2) 사전 열 이름 변경 및 정제

<details>

<summary>감정 사전 정제</summary>

```{r}
#| label: 감정 사전 정제
#| include: true
#| warning: false

senti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)

senti_dic_df %>%

mutate(emotion = ifelse(sScore >= 1, "긍정", ifelse(sScore <= -1, "부정", "중립"))) %>%

count(emotion)

knu_dic_df <- senti_dic_df %>%

filter(!is.na(sScore))



```

</details>

##### 3) 감정어 분석

<details>

<summary>야놀자 감정어 분석</summary>

```{r}
#| label: 야놀자 감정어 분석
#| include: true
#| warning: false

#상위 15개 감정어 분석(단어 갯수 2개 이상)
yanolja_senti_df <- yanolja_tk %>%

unnest_tokens(word, 본문, token = pos) %>%

separate(col = word, into = c("word", "morph"), sep = "/" ) %>%

inner_join(knu_dic_df) %>%

count(word, sScore, sort = T) %>%

filter(str_length(word) > 1) %>%

mutate(word = reorder(word, n)) %>%

slice_head(n = 15)

#감정어 그래프
yanolja_senti_df %>%

ggplot()+

geom_col(aes(n, word, fill = sScore), show.legend = F)

#감정 분석 점수
yanolja_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(is.na(sScore), 0, sScore)) %>%

arrange(sScore)

#긍정 부정 단어 갯수
yanolja_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(sScore >= 1, "긍정", ifelse(sScore <= -1, "부정", "중립"))) %>%

count(sScore)

# 감정 점수
yanolja_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(is.na(sScore), 0, sScore)) %>%

summarise(emotion = sum(sScore))
```

</details>

감정어 분석을 통해 살펴본 야놀자는 긍정적인 표현으로 여행 테마의 할인, 함께, 혜택의 표현이 있었고 주식 테마의 가치, 대상의 표현이 있었다. 부정적인 표현으로는 코로나로 인한 바이러스, 숙박 및 코로나로 인한 소비자의 피해에 대한 것이 있었다.

감정 점수로는 긍정: 19207 부정: 5308 중립: 268 종합: 16144 이며 긍정적인 점수가 높음을 알 수 있다.

<details>

<summary>야놀자 감정 단어 상위 50개 그래프</summary>

```{r}
#| label: 야놀자 감정 단어 상위 50개 그래프
#| include: true
#| warning: false

yanolja_tk %>%

unnest_tokens(word, 본문) %>%

inner_join(knu_dic_df) %>%

mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%

filter(emotion != "중립") %>%

count(word, emotion, sort = T) %>%

mutate(word = reorder(word, n)) %>%

filter(str_length(word) > 1) %>%

top_n(20) %>%

ggplot(aes(word, n, fill = emotion)) +

geom_col(show.legend = FALSE) +

facet_wrap(~emotion, scales = "free_y") +

labs(y = "단어 빈도", x = "감정 단어", title = "야놀자 긍정어 부정어") +

coord_flip()
```

</details>

야놀자의 긍정어 부정어를 조금 더 자세히 살펴보면 긍정적 표현으로 **함께**라는 표현이 가장 많이 나왔음을 확인할 수 있다.

기사를 통한 분석으로는 야놀자는 여행업체이며 IT적 성장과 기업 상장에 관심을 가지고 있는 유니콘 회사이다. 그러다보니 다수의 기업들과 "함께" 무엇인가를 만들고 기획하는 일이 많았다.

부정적 표현으로 **피해**가 가장 많이 나왔음을 확인할 수 있다. 야놀자가 경험한 피해와 플랫폼으로 인한 피해 2가지로 나누어볼 수 있다.

우선 야놀자는 여기어때와 법정 소송을 진행중에 있다. 여기어때에서 불법적으로 야놀자가 보유한 정보를 크롤링한 혐의로 약 3년간 법정 소송을 진행중이다.

두번째로 야놀자를 이용하는 고객들이 야놀자 서비스로 인해 경험한 피해가 다수 있으며 이에 대한 미흡한 대처가 있었음을 알 수 있다.

<details>

<summary>야놀자 감정 워드클라우드</summary>

```{r}
#| label: 야놀자 감정 워드클라우드
#| include: true
#| warning: false

yanolja_tk %>%

unnest_tokens(word, 본문) %>%

inner_join(knu_dic_df) %>%

mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%

filter(emotion != "중립") %>%

count(word, emotion, sort = T) %>%

filter(str_length(word) > 1) %>%

reshape2::acast(word ~ emotion, value.var = "n", fill = 0) %>%

comparison.cloud(colors = c("blue", "red"), max.words = 50)

```

</details>

<details>

<summary>여기어때 감정어 분석</summary>

```{r}
#| label: 여기어때 감정어 분석 
#| include: true
#| warning: false

#상위 15개 감정어 분석(단어 갯수 2개 이상)

hah_senti_df <- hah_tk %>%

unnest_tokens(word, 본문, token = pos) %>%

separate(col = word, into = c("word", "morph"), sep = "/" ) %>%

inner_join(knu_dic_df) %>%

count(word, sScore, sort = T) %>%

filter(str_length(word) > 1) %>%

mutate(word = reorder(word, n)) %>%

slice_head(n = 15)

#감정어 그래프

hah_senti_df %>%

ggplot()+

geom_col(aes(n, word, fill = sScore), show.legend = F)


#감정 분석 점수
hah_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(is.na(sScore), 0, sScore)) %>%

arrange(sScore)


#긍정 부정 단어 갯수

hah_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(sScore >= 1, "긍정", ifelse(sScore <= -1, "부정", "중립"))) %>%

count(sScore)

#감정 점수

hah_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(is.na(sScore), 0, sScore)) %>%

summarise(emotion = sum(sScore))

```

</details>

감정어 분석을 통해 살펴본 여기어때는 긍정적인 표현으로 여행 테마의 할인, 함께, 이벤트라는 표현이 있었다. 부정적인 표현으로는 코로나로 인한 바이러스, 숙박 및 코로나로 인한 소비자의 피해에 대한 것이 있었다. 전체적인 감정어는 야놀자와 유사한 것으로 보인다.

감정 점수로는 긍정: 5331 부정: 1155 중립: 27 종합: 5120 이며 긍정적인 점수가 높음을 알 수 있다. 야놀자보다 기사의 양이 부족하지만, 그럼에도 불구하고 상대적인 종합 감정 점수는 여기어때가 더 높게 평가되고 있음을 파악할 수 있다.

<details>

<summary>여기어때 감정 단어 상위 50개 그래프</summary>

```{r}
#| label: 여기어때 감정 단어 상위 50개 그래프
#| include: true
#| warning: false

hah_tk %>%

unnest_tokens(word, 본문) %>%

inner_join(knu_dic_df) %>%

mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%

filter(emotion != "중립") %>%

count(word, emotion, sort = T) %>%

mutate(word = reorder(word, n)) %>%

filter(str_length(word) > 1) %>%

top_n(20) %>%

ggplot(aes(word, n, fill = emotion)) +

geom_col(show.legend = FALSE) +

facet_wrap(~emotion, scales = "free_y") +

labs(y = "단어 빈도", x = "감정 단어", title = "여기어때 긍정어 부정어") +

coord_flip()

```

</details>

여기어때의 긍정어 부정어를 조금 더 자세히 살펴보면 긍정적 표현으로 **함께**라는 표현이 가장 많이 나왔음을 확인할 수 있다.

여기어때도 야놀자와 유사하게 여행과 관련하여 콜라보레이션을 많이 했기 때문에 이런 결과를 확인할 수 있었는데, 야놀자보다도 더 여행쪽에 표현들이 긍정어에 많이 있음을 확인할 수 있다.

부정적 표현으로 **피해**가 가장 많이 나왔음을 확인할 수 있다. 여기어때는 야놀자의 정보를 불법적으로 크롤링하여 법정소송을 진행하고 있기 때문에 많이 나온 것으로 확인된다.

<details>

<summary>여기어때 감정 워드클라우드</summary>

```{r}
#| label: 여기어때 감정 워드클라우드
#| include: true
#| warning: false

hah_tk %>%

unnest_tokens(word, 본문) %>%

inner_join(knu_dic_df) %>%

mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%

filter(emotion != "중립") %>%

count(word, emotion, sort = T) %>%

filter(str_length(word) > 1) %>%

reshape2::acast(word ~ emotion, value.var = "n", fill = 0) %>%

comparison.cloud(colors = c("blue", "red"), max.words = 50)

```

------------------------------------------------------------------------

### 4. 주제모형

> 모형 구축을 위해 기준점이 되는 자료 열 "press", "cat" 등을 새롭게 불러와 자료를 수집하고
>
> 수집한 기사의 중복 기사를 삭제하고 기사별 열 번호를 기입하여 분석에 용의하게 정제했다.
>
> 많은 주제 중 경제와 문화 측면의 기사가 가장 많아 경제로 묶었다.
>
> 다양한 언론사를 야당지와 여당지로 추가 분류하였고 속하지 않은 언론사는 여당지로 분류하였다.

##### 1) 모델링을 위한 자료 수집

```{r}
#| label: 자료수집
#| include: false
#| warning: false

#야놀자
yanolja_sub <- readxl::read_excel("C:/Users/YH JUNG/Documents/R/GIT/residence/data/yanolja_after_covid_20190201-20220930.xlsx") %>%

select(일자, 제목, 본문, 언론사, cat = `통합 분류1`, 키워드)

#여기어때
hah_sub <- readxl::read_excel("C:/Users/YH JUNG/Documents/R/GIT/residence/data/hah_after_covid_20190201-20220930.xlsx") %>%

select(일자, 제목, 본문, 언론사, cat = `통합 분류1`, 키워드)
```

##### 2) 자료 정제

<details>

<summary>야놀자 자료 정제</summary>

```{r}
#| label: 야놀자 자료 정제
#| include: true
#| warning: false

yanolja_sub2 <- yanolja_sub %>%

distinct(제목, .keep_all = T) %>%

mutate(ID = factor(row_number())) %>%

mutate(week = week(ymd(일자))) %>%

unite(제목, 본문, col = "text", sep = " ") %>%

mutate(text = str_squish(text)) %>%

mutate(press = case_when(

언론사 == "조선일보" ~ "야당지",

언론사 == "중앙일보" ~ "야당지",

언론사 == "동앙일보" ~ "야당지",

언론사 == "국민일보" ~ "야당지",

언론사 == "문화일보" ~ "야당지",

언론사 == "한국경제" ~ "야당지",

언론사 == "경향신문" ~ "여당지",

TRUE ~ "여당지") ) %>%

separate(cat, sep = ">", into = c("cat", "cat2")) %>%

select(-cat2) %>%

mutate(catSoc = case_when( cat == "경제" ~ "경제면",
                           cat == "문화" ~ "경제면", 
                           TRUE ~ "비경제면") )

#주제별 갯수
yanolja_sub2 %>% count(cat, sort = T)
```

\#####

</details>

<details>

<summary>여기어때 자료 정제</summary>

```{r}
#| label: 여기어때 자료 정제
#| include: true
#| warning: false

hah_sub2 <- hah_sub %>%

distinct(제목, .keep_all = T) %>%

mutate(ID = factor(row_number())) %>%

mutate(week = week(ymd(일자))) %>%

unite(제목, 본문, col = "text", sep = " ") %>%

mutate(text = str_squish(text)) %>%

mutate(press = case_when(

언론사 == "조선일보" ~ "야당지",

언론사 == "중앙일보" ~ "야당지",

언론사 == "동앙일보" ~ "야당지",

언론사 == "국민일보" ~ "야당지",

언론사 == "문화일보" ~ "야당지",

언론사 == "한국경제" ~ "야당지",

언론사 == "경향신문" ~ "여당지",

TRUE ~ "여당지") ) %>%

separate(cat, sep = ">", into = c("cat", "cat2")) %>%

select(-cat2) %>%

mutate(catSoc = case_when(cat == "경제" ~ "경제면",
                          cat == "문화" ~ "경제면",
                          TRUE ~ "비경제면") )

#여기어때 주제별 갯수
hah_sub2 %>% count(cat, sort = T)
```

</details>

##### 3) 토큰화

<details>

<summary>야놀자 토큰화</summary>

```{r}
#| label: 야놀자 토큰화
#| include: true
#| warning: false

fullchar_v <- "ㆍ|ㅣ|‘|’|“|”|○|●|◎|◇|◆|□|■|△|▲|▽|▼|〓|◁|◀|▷|▶|♤|♠|♡|♥|♧|♣|⊙|◈|▣"


#야놀자 토큰화
yanolja_S <- yanolja_sub2 %>%

mutate(키워드 = str_remove_all(키워드, "[^(\\w+|\\d+|,)]")) %>%

mutate(키워드 = str_remove_all(키워드, fullchar_v)) %>%

unnest_tokens(word, 키워드, token = "regex", pattern = ",")

#토큰화 후 데이터 결합

yanolja_C <- yanolja_S %>%

group_by(ID) %>%

summarise(text2 = str_flatten(word, " ")) %>%

ungroup() %>%

inner_join(yanolja_sub2, by = "ID")
```

</details>

<details>

<summary>여기어때 토큰화</summary>

```{r}
#| label: 여기어때 토큰화
#| include: true
#| warning: false

hah_S <- hah_sub2 %>%

mutate(키워드 = str_remove_all(키워드, "[^(\\w+|\\d+|,)]")) %>%

mutate(키워드 = str_remove_all(키워드, fullchar_v)) %>%

unnest_tokens(word, 키워드, token = "regex", pattern = ",")

#여기어때 데이터 결합

hah_C <- hah_S %>%

group_by(ID) %>%

summarise(text2 = str_flatten(word, " ")) %>%

ungroup() %>%

inner_join(hah_sub2, by = "ID")
```

</details>

##### 4) stm 말뭉치

<details>

<summary>야놀자 stm 말뭉치 & 객체 할당</summary>

```{r}
#| label: 야놀자 stm 말뭉치 & 객체 할당
#| include: true
#| warning: false

processed_yanol <- yanolja_C %>% 
  textProcessor(documents = yanolja_C$text2,
                metadata = .,
                wordLengths = c(2, Inf))

out_yanol <- prepDocuments(processed_yanol$documents,
                           processed_yanol$vocab,
                           processed_yanol$meta,
                           lower.thresh = 0)

summary(out_yanol)

# 모형구축을 위한 객체 저장
docs_yanol <- out_yanol$documents

vocab_yanol <- out_yanol$vocab

meta_yanol <- out_yanol$meta
```

</details>

<details>

<summary>여기어때 stm 말뭉치 & 객체 할당</summary>

```{r}
#| label: 여기어때 stm 말뭉치 & 객체 할당
#| include: true
#| warning: false

processed_hah <- hah_C %>% textProcessor(documents = hah_C$text2,
                                         metadata = .,
                                         wordLengths = c(2, Inf))


out_hah <-prepDocuments(processed_hah$documents,
                        processed_hah$vocab,
                        processed_hah$meta,
                        lower.thresh = 0)

# 모형구축을 위한 객체 할당
summary(out_hah)

docs_hah <- out_hah$documents

vocab_hah <- out_hah$vocab

meta_hah <- out_hah$meta

```

</details>

##### 5) 공변인 분석

```{r}
#| label: 토픽 갯수 정하기
#| include: false
#| warning: false
#| eval: true
#주제 갯수
topicN <- c(3, 10)

storage_yanol <- searchK(docs_yanol, vocab_yanol, K = topicN)

storage_hah <- searchK(docs_hah, vocab_hah, K = topicN)
```

토픽 모델링을 하기 전에 모델을 1개부터 100개까지 코드를 진행해보았고 10개 이상부터 유의미한 토픽 분석이 될 것으로 확인되어 10개로 정했다.

<details>

<summary>야놀자 주제모형(공변인) 분석</summary>

```{r}
#| label: 야놀자 주제모형(공변인) 분석
#| include: true
#| warning: false

#시스템 시간
t1 <- Sys.time()
t2 <- Sys.time()
#주제모형 구성
meta_fit_yanol <- stm(documents = docs_yanol,
                      vocab = vocab_yanol,
                      data = meta_yanol,
                      K = 10,
                      prevalence =~ press + s(week, 6), 
                      max.em.its = 75, 
                      verbose = F, 
                      init.type = "Spectral",
                      seed = 37)
```

</details>

<details>

<summary>여기어때 주제모형(공변인) 분석</summary>

```{r}
#| label: 여기어때 주제모형(공변인) 분석
#| include: true
#| warning: false

plot(storage_hah)

meta_fit_hah <- stm(documents = docs_hah,
                    vocab = vocab_hah,
                    data = meta_hah,
                    K = 10,
                    prevalence =~ press + s(week, 6),
                    max.em.its = 75,
                    verbose = F,
                    init.type = "Spectral",
                    seed = 37)
```

</details>

##### 6) 주제 이름 짓기

<details>

<summary>야놀자 주제이름 짓기</summary>

```{r}
#| label: 야놀자 주제이름 짓기
#| include: true
#| warning: false

labelTopics(meta_fit_yanol)

#주제 이름 데이터 프레임에 저장
topic_name_yanol <- tibble(topic = 1:10,
                           name = c("1. 연휴, 여행",
                                    "2. 야놀자 클라우드 시스템",
                                    "3. 강원도 산불 피해자 지원",
                                    "4. 국정감사",
                                    "5. 온라인플렛폼공정화",
                                    "6. 인터파크 인수",
                                    "7. 유니콘 기업",
                                    "8. 결제 할인",
                                    "9. NFT",
                                    "10. 야놀자 투자") )

#주제별 상위 7개 단어목록을 데이터 프레임에 저장
td_beta_yanol <- meta_fit_yanol %>% tidy(matrix = 'beta')

term_topic_name_yanol <- td_beta_yanol %>%

group_by(topic) %>%

slice_max(beta, n = 7) %>%

left_join(topic_name_yanol, by = "topic")
```

</details>

<details>

<summary>여기어때 주제이름 짓기</summary>

```{r}
#| label: 여기어때 주제이름 짓기
#| include: true
#| warning: false

labelTopics(meta_fit_hah)

#주제 이름 데이터 프레임에 저장
topic_name_hah <- tibble(topic = 1:10,
                         name = c("1. 여기어때 인수",
                                  "2. 경상북도 콜라보",
                                  "3. 불법크롤링 법정 문제",
                                  "4. 유니콘 기업",
                                  "5. 현대카드 콜라보",
                                  "6. 고객정보 대량유출",
                                  "7. 경기도 콜라보",
                                  "8. 여행 플랫폼",
                                  "9. 반려동물 여행",
                                  "10. 해외여행") )

#주제별 상위 7개 단어목록을 데이터 프레임에 저장
td_beta_hah <- meta_fit_hah %>% tidy(matrix = 'beta')

term_topic_name_hah <-
  
  td_beta_hah %>%
  
  group_by(topic) %>%
  
  slice_max(beta, n = 7) %>%
  
  left_join(topic_name_hah, by = "topic")
```

</details>

토픽에 대한 단어들을 통해 주제를 정했으며, 유사한 주제의 경우 차이점을 두기위해 관련 기사들을 찾아보고 단어들을 확인해 보았다.

##### 7) 주제별 단어 분포표

<details>

<summary>야놀자 주제별 단어 분포표</summary>

```{r}
#| label: 야놀자 주제별 단어 분포표
#| include: true
#| warning: false

term_topic_name_yanol %>%
  ggplot(aes(x = beta,
             y = reorder_within(term, beta, name),
             fill = name)) +
  geom_col(show.legend = F) +
  
  facet_wrap(~name, scales = "free") +
  
  scale_y_reordered() + 
  
  labs(x = expression("단어 확률분포:"~beta), y = NULL,
       title = "야놀자 주제별 단어 확률 분포",
       subtitle = "주제별로 다른 단어들로 군집") +
  
  theme(plot.title = element_text(size = 20))
```

</details>

야놀자 주제별 단어 확률 분포를 통해 가장 많이 이야기되는 내용을 중심으로 살펴보았다. 인터파크 인수, 블록체인 루니버스 주제가 가장 밀집도 있게 보여졌다.

인터파크에서 야놀자를 인수하며 야놀자의 시장과 사업이 증가한 것을 확인할 수 있고, 야놀자의 주된 행사가 결제, 할인, 해택 등이라는 것을 확인할 수 있다.

<details>

<summary>여기어때 주제별 단어 분포표</summary>

```{r}
#| label: 여기어때 주제별 단어 분포표
#| include: true
#| warning: false

term_topic_name_hah %>%
  
  ggplot(aes(x = beta,
             y = reorder_within(term, beta, name),
             fill = name)) +
  
  geom_col(show.legend = F) +
  
  facet_wrap(~name, scales = "free") +
  
  scale_y_reordered() +
  
  labs(x = expression("단어 확률분포:"~beta),
       y = NULL,
       title = "여기어때 주제별 단어 확률 분포",
       subtitle = "주제별로 다른 단어들로 군집") +
  
  theme(plot.title = element_text(size = 20))
```

</details>

여기어때에서 밀집도가 있게 나타난 주제는 유니콘 기업과 경기도 콜라보이다.

여기어때는 유니콘 기업으로 숙박 플랫폼을 구축하여 기업의 가치를 높이며 여러 업체와의 상호작용을 통해 숙박업에서 큰 역할을 하고 있다는 것을 주제 모형을 통해 확인할 수 있으며 주된 수익 창출이 이런 중계 역할을 통한 수수료 수익임을 알 수 있다.

또한 여기어때가 경기도와 콜라보레이션을 하여 자신의 PR적 측면을 강화했다. 경기도의 여행지와 음식점 등 관광 촉진을 위해 다양한 영상과 캠페인을 진행하였고 콘텐츠 제작과 광고에도 힘쓴 것을 단어를 통해 확인할 수 있다.

##### 8) 감마를 통한 주제 관련보도 상위 주제어

> 감마는 주제어의 문서 분포를 확인하기 위해 쓰지만 분석 자료로 사용하지 않고 감마의 평균값을 통하여 주제 관련 보도의 상위 주제어를 파악할 수 있다.

<details>

<summary>야놀자 감마 분석을 통한 상위 주제어</summary>

```{r}
#| label: 야놀자 감마 분석을 통한 상위 주제어
#| include: true
#| warning: false

#감마분석
td_gamma_yanol <- meta_fit_yanol %>% tidy(matrix = 'gamma')

#단어분포 자료를 통해 주제별 상위 7개 단어 선정
top_terms_yanol <-

td_beta_yanol %>%

group_by(topic) %>%

slice_max(beta, n = 7) %>%

select(topic, term) %>%

summarise(terms = str_flatten(term, collapse = ","))

top_terms_yanol
#주제별 감마 평균 계산
gamma_terms_yanol <-

td_gamma_yanol %>%

group_by(topic) %>%

summarise(gamma = mean(gamma)) %>%

left_join(top_terms_yanol, by = 'topic') %>% 

left_join(topic_name_yanol, by = 'topic')

gamma_terms_yanol
```

</details>

<details>

<summary>여기어때 감마 분석을 통한 상위 주제어</summary>

```{r}
#| label: 여기어때 감마 분석을 통한 상위 주제어
#| include: true
#| warning: false

#감마분석
td_gamma_hah <- meta_fit_hah %>% tidy(matrix = 'gamma')

#단어분포 자료를 통해 주제별 상위 7개 단어 선정
top_terms_hah <-

td_beta_hah %>%

group_by(topic) %>%

slice_max(beta, n = 7) %>%

select(topic, term) %>%

summarise(terms = str_flatten(term, collapse = ","))

top_terms_hah

#주제별 감마 평균 계산
gamma_terms_hah <-

td_gamma_hah %>%

group_by(topic) %>%

summarise(gamma = mean(gamma)) %>%

left_join(top_terms_hah, by = 'topic') %>%

left_join(topic_name_hah, by = 'topic')

gamma_terms_hah
```

</details>

##### 9) 상위 주제어 그래프

<details>

<summary>야놀자 상위 주제어 그래프</summary>

```{r}
#| label: 야놀자 상위 주제어 그래프
#| include: true
#| warning: false

gamma_terms_yanol %>%
  
  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +
  
  geom_col(show.legend = F) +
  
  geom_text(aes(label = round(gamma, 2)),
            hjust = 1.15) + 
  
  geom_text(aes(label = terms),
            hjust = -0.05) + 
  
  scale_x_continuous(expand = c(0, 0), 
                     limit = c(0, .8)) + 
  
  labs(x = expression("문서 확률분포"~(gamma)), 
       y = NULL,
       title = "야놀자 관련 상위 주제어",
       subtitle = "주제별로 기여도가 높은 단어 중심") +
  
  theme(plot.title = element_text(size = 20))
```

</details>

야놀자는 자체 클라우드 시스템이 가장 주목받고 있음을 확인할 수 있다.

IT 기업이 아니냐는 기사가 있을 정도로 자체적으로 개발하고 관리하는 클라우드 시스템이 야놀자의 가치와 서비스 측면을 높이는 데에 기여하고 있다.

또한 야놀자도 유니콘 기업으로 투자, 스타트업, 상장 등의 내용이 많이 주목받고 있다. 여행 업체이지만 다른 분야로 나아가기 위해 노력하고 있다는 것을 확인할 수 있다.

<details>

<summary>여기어때 상위 주제어 그래프</summary>

```{r}
#| label: 여기어때 상위 주제어 그래프
#| include: true
#| warning: false

gamma_terms_hah %>%

ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +

geom_col(show.legend = F) +

geom_text(aes(label = round(gamma, 2)), 
          hjust = 1.15) + 

geom_text(aes(label = terms),
          hjust = -0.05) + 

scale_x_continuous(expand = c(0, 0), 
                   limit = c(0, .8)) + 

labs(x = expression("문서 확률분포"~(gamma)),
     y = NULL,
     title = "여기어때 관련 상위 주제어",
     subtitle = "주제별로 기여도가 높은 단어 중심") +
  
theme(plot.title = element_text(size = 20))
```

</details>

여기어때는 여행과 관련된 주제가 상위 주제를 차지하고 있다. 해택적인 부분, 여행적인 부분에 있어서 더욱 관심을 받고 있다.

### 정리

> 야놀자와 여기어때를 비교하며 단어적 차이를 살펴본 결과 분명하게 두드러지는 부분은 2가지가 있었다.
>
> 1)  여행 플랫폼
>
> 야놀자와 여기어때는 모델링을 통한 비교 분석을 해도 콜라보레이션, 여행, 할인 등 **여행 관련 주제**가 매우 유사한 것을 알 수 있다. 유사한 플랫폼이기 때문에 **크롤링 관련 법정 소송**이 3년동안 진행되고 있는 것도 그렇고 얼마나 많은 숙소, 식당과 제휴를 맺느냐에 따라 기업의 성적이 달라지기 때문에 매우 민감한 사항인 것을 알 수 있다.
>
> 2)  기술력
>
> 코로나 이후 여행 업체가 주춤하면서 **여기어때는 현상 유지**를 하기 위해 노력한 것으로 보인다. 다시 말해 자신의 플랫폼이 망하지 않게 만들기 위해 지금의 플랫폼을 조금 더 향상시기기 보다 보완하는 것에 중점을 두었다.
>
> 하지만 **야놀자**는 코로나로 인해 여행업체가 주춤되는 것을 기회로 삼아서 **자체적인 시스템 개발**에 힘을 더했다. **블록체인, NFT**와 같이 수익원을 창출할 수 있는 기술력을 발전시켰고 이러한 기술력을 바탕으로 서비스에 적용하다보니, 여기어때와의 성장률에 있어서 격차가 나고 있다는 것을 확인할 수 있었다.
