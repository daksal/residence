---
title: "야놀자 & 여기 어때"
output:
  html_document: default
  pdf_document: default
date: "2022-10-04"
---

기간: 2022.01 \~ 2022.09.18

빅카인즈 키워드 검색을 통해 '야놀자'와 '여기 어때' 기업에 대한 기사를 분석함

분석 기간은 2022년 01월부터 09월까지의 기사를 다루었다.

기사의 갯수로 야놀자는 5808건, 여기 어때는 1075건을 분석했다.

분석 순서로는 **총빈도, 상대빈도, 감정어 분석, 주제모형** 순으로 분석했다.

### 1. 분석에 앞선 기본적인 준비

##### *1) 패키지 설치 및 불러오기*

```{r 패키지 불러오기, include=FALSE, warning=FALSE}

c( "rio", "psych", "psychTools", "skimr", "janitor", 
   
   "tidyverse", "tidytable", "tidymodels", "lm.beta",
   
   "GGally", "ggforce", "gt", "mdthemes", "patchwork",
   
   "r2symbols", "equatiomatic", "purrr", "palmerpenguins",
   
   "textdata", "tidytext", "epubr", "stm", "quarto", "wordcloud",
   
   "RcppMeCab", "KoNLP", "tidyr", "dplyr", "tidylo", "lubridate"
   
) -> pkg 

lapply(pkg, require, ch = T)

sapply(pkg, function(x){

  if(!require(x, ch = T)) install.packages(x)

  library(x, ch = T)

})
```

##### *2) 파일 경로 설정*

```{r}
#| label: 파일경로 설정
#| include: false
#| warning: false

setwd("C:/Users/YH JUNG/Documents/R/GIT/residence/data")

getwd()
```

##### *3) 감정어 사전 설치 및 불러오기*

```{r}
#| label: 감정어 사전 다운 및 설치
#| include: false
#| warning: false

url_v <- "https://github.com/park1200656/KnuSentiLex/archive/refs/heads/master.zip"

dest_v <- "data/knusenti.zip"

download.file(url = url_v, destfile = dest_v, mode = "wb")

list.files("data/KnuSentiLex-master/")
```

##### *4) 자료 불러오기 및 자료 정제*

```{r}
#| label: 빅카인즈 야놀자 & 여기어때 자료
#| include: false
#| warning: false

# 야놀자
yanolja_df <- readxl::read_excel("C:/Users/YH JUNG/Documents/R/GIT/residence/data/yanolja_after_covid_20190201-20220930.xlsx") %>%
  
select.(제목, 언론사, 본문, URL)

yanolja_tk <- yanolja_df %>%
  
drop_na() %>%
  
unnest_tokens(word, 제목, token = pos) %>%
  
separate(word, c("word", "pos"), sep = "/") %>%
  
filter(pos == 'nng')

#여기어때
hah_df <- readxl::read_excel("C:/Users/YH JUNG/Documents/R/GIT/residence/data/hah_after_covid_20190201-20220930.xlsx") %>%
  
select.(제목, 언론사, 본문, URL)

hah_tk <- hah_df %>%
  
drop_na() %>%
  
unnest_tokens(word, 제목, token = pos) %>%
  
separate(word, c("word", "pos"), sep = "/") %>%
  
filter(pos == 'nng')
```

### 2. 총빈도 & 상대빈도

#### 1) 총빈도

```{r}
#| label: 야놀자 총빈도
#| include: true
#| warning: false

yanolja_total <- yanolja_tk %>%

count(word, sort = T) %>%

slice_max(n, n = 15) %>%

ggplot(aes(x = n,

y = reorder(word, n))) +

geom_col(show.legend = F)

yanolja_total
```

```{r}
#| label: 여기 어때 총빈도
#| include: true
#| warning: false

hah_total <- hah_tk %>%

count(word, sort = T) %>%

slice_max(n, n = 15) %>%

ggplot(aes(x = n,

y = reorder(word, n))) +

geom_col(show.legend = F)

hah_total
```

#### 2) 상대빈도

```{r}
#| label: 상대빈도
#| include: true
#| warning: false

yanolja_df %>% 
  unnest_tokens(output = word, input = 본문, token  = pos) %>% 
  separate(col = word, 
           into = c("word", "pos"),
           sep = "/") %>% 
  filter(pos == "nng")-> yj_df

hah_df %>% 
  unnest_tokens(output = word, input = 본문, token  = pos) %>% 
  separate(col = word, 
           into = c("word", "pos"),
           sep = "/") %>% 
  filter(pos == "nng") -> hh_df

#상대빈도 결합
bind_rows(yj_df, hh_df, .id = "기업")  %>% 
  filter(str_length(word) > 1) %>%
  filter(word != "여기") %>% 
  filter(word != "어때") %>% 
  filter(word != "야놀자") %>% 
  count(word, 기업) %>% 
  bind_log_odds(set = 기업,
                feature = word, 
                n = n) %>% 
  arrange(-log_odds_weighted) -> weighted_log_odds_df

weighted_log_odds_df %>%
  group_by(기업 = ifelse(기업 > 1, "여기어때", "야놀자")) %>%
  slice_max(abs(log_odds_weighted), n = 15) %>%
  ggplot(aes(x = log_odds_weighted,
             y = reorder(word, log_odds_weighted),
             fill = 기업)) +
  geom_col(show.legend = F) +
  facet_wrap(~기업, scale = "free")
```

### 3. 감정분석

##### 1) 사전 내용 선택

```{r}
#| label: 사전 내용 선택
#| include: false
#| warning: false

senti_name_v <- list.files("data/KnuSentiLex-master/.")[9]

senti_dic_df <- read_tsv("data/KnuSentiLex-master/SentiWord_Dict.txt", col_names = F)

```

##### 2) 사전 열 이름 변경 및 정제

```{r}
#| label: 감정 사전 정제
#| include: false
#| warning: false

senti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)

senti_dic_df %>%

mutate(emotion = ifelse(sScore >= 1, "긍정", ifelse(sScore <= -1, "부정", "중립"))) %>%

count(emotion)

knu_dic_df <- senti_dic_df %>%

filter(!is.na(sScore))



```

##### 3) 감정어 분석

```{r}
#| label: 야놀자 감정어 분석
#| include: true
#| warning: false

#상위 15개 감정어 분석(단어 갯수 2개 이상)
yanolja_senti_df <- yanolja_tk %>%

unnest_tokens(word, 본문, token = pos) %>%

separate(col = word, into = c("word", "morph"), sep = "/" ) %>%

inner_join(knu_dic_df) %>%

count(word, sScore, sort = T) %>%

filter(str_length(word) > 1) %>%

mutate(word = reorder(word, n)) %>%

slice_head(n = 15)

#감정어 그래프
yanolja_senti_df %>%

ggplot()+

geom_col(aes(n, word, fill = sScore), show.legend = F)

#감정 분석 점수
yanolja_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(is.na(sScore), 0, sScore)) %>%

arrange(sScore)

#긍정 부정 단어 갯수
yanolja_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(sScore >= 1, "긍정", ifelse(sScore <= -1, "부정", "중립"))) %>%

count(sScore)

# 감정 점수
yanolja_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(is.na(sScore), 0, sScore)) %>%

summarise(emotion = sum(sScore))
```

```{r}
#| label: 야놀자 감정 단어 상위 50개 그래프
#| include: true
#| warning: false

yanolja_tk %>%

unnest_tokens(word, 본문) %>%

inner_join(knu_dic_df) %>%

mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%

filter(emotion != "중립") %>%

count(word, emotion, sort = T) %>%

mutate(word = reorder(word, n)) %>%

filter(str_length(word) > 1) %>%

top_n(50) %>%

ggplot(aes(word, n, fill = emotion)) +

geom_col(show.legend = FALSE) +

facet_wrap(~emotion, scales = "free_y") +

labs(y = "단어 빈도", x = "감정 단어", title = "야놀자 긍정어 부정어") +

coord_flip()
```

```{r}
#| label: 야놀자 감정 워드클라우드
#| include: true
#| warning: false

yanolja_tk %>%

unnest_tokens(word, 본문) %>%

inner_join(knu_dic_df) %>%

mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%

filter(emotion != "중립") %>%

count(word, emotion, sort = T) %>%

filter(str_length(word) > 1) %>%

reshape2::acast(word ~ emotion, value.var = "n", fill = 0) %>%

comparison.cloud(colors = c("blue", "red"), max.words = 50)

```

```{r}
#| label: 여기 어때 감정어 분석 
#| include: true
#| warning: false

#상위 15개 감정어 분석(단어 갯수 2개 이상)

hah_senti_df <- hah_tk %>%

unnest_tokens(word, 본문, token = pos) %>%

separate(col = word, into = c("word", "morph"), sep = "/" ) %>%

inner_join(knu_dic_df) %>%

count(word, sScore, sort = T) %>%

filter(str_length(word) > 1) %>%

mutate(word = reorder(word, n)) %>%

slice_head(n = 15)

#감정어 그래프

hah_senti_df %>%

ggplot()+

geom_col(aes(n, word, fill = sScore), show.legend = F)


#감정 분석 점수
hah_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(is.na(sScore), 0, sScore)) %>%

arrange(sScore)


#긍정 부정 단어 갯수

hah_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(sScore >= 1, "긍정", ifelse(sScore <= -1, "부정", "중립"))) %>%

count(sScore)

#감정 점수

hah_tk %>%

unnest_tokens(word, 본문) %>%

left_join(knu_dic_df) %>%

mutate(sScore = ifelse(is.na(sScore), 0, sScore)) %>%

summarise(emotion = sum(sScore))

```

```{r}
#| label: 여기 어때 감정 단어 상위 50개 그래프
#| include: true
#| warning: false

hah_tk %>%

unnest_tokens(word, 본문) %>%

inner_join(knu_dic_df) %>%

mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%

filter(emotion != "중립") %>%

count(word, emotion, sort = T) %>%

mutate(word = reorder(word, n)) %>%

filter(str_length(word) > 1) %>%

top_n(50) %>%

ggplot(aes(word, n, fill = emotion)) +

geom_col(show.legend = FALSE) +

facet_wrap(~emotion, scales = "free_y") +

labs(y = "단어 빈도", x = "감정 단어", title = "여기어때 긍정어 부정어") +

coord_flip()

```

```{r}
#| label: 여기 어때 감정 워드크라우드
#| include: true
#| warning: false

hah_tk %>%

unnest_tokens(word, 본문) %>%

inner_join(knu_dic_df) %>%

mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%

filter(emotion != "중립") %>%

count(word, emotion, sort = T) %>%

filter(str_length(word) > 1) %>%

reshape2::acast(word ~ emotion, value.var = "n", fill = 0) %>%

comparison.cloud(colors = c("blue", "red"), max.words = 50)

```

### 4. 주제모형

모형 구축을 위해 기준점이 되는 자료 열 "press", "cat" 등을 새롭게 불러와 자료를 수집하고

수집한 기사의 중복 기사를 삭제하고 기사별 열 번호를 기입하여 분석에 용의하게 정제했다.

많은 주제 중 경제와 문화 측면의 기사가 가장 많아 경제로 묶었다.

다양한 언론사를 야당지와 여당지로 추가 분류하였고 속하지 않은 언론사는 여당지로 분류하였다.

##### 1) 모델링을 위한 자료 수집

```{r}
#| label: 자료수집
#| include: false
#| warning: false

#야놀자
yanolja_sub <- readxl::read_excel("C:/Users/YH JUNG/Documents/R/GIT/residence/data/yanolja_after_covid_20190201-20220930.xlsx") %>%

select(일자, 제목, 본문, 언론사, cat = `통합 분류1`, 키워드)

#여기 어때
hah_sub <- readxl::read_excel("C:/Users/YH JUNG/Documents/R/GIT/residence/data/hah_after_covid_20190201-20220930.xlsx") %>%

select(일자, 제목, 본문, 언론사, cat = `통합 분류1`, 키워드)
```

##### 2) 자료 정제

```{r}
#| label: 야놀자 자료 정제
#| include: true
#| warning: false

yanolja_sub2 <- yanolja_sub %>%

distinct(제목, .keep_all = T) %>%

mutate(ID = factor(row_number())) %>%

mutate(week = week(ymd(일자))) %>%

unite(제목, 본문, col = "text", sep = " ") %>%

mutate(text = str_squish(text)) %>%

mutate(press = case_when(

언론사 == "조선일보" ~ "야당지",

언론사 == "중앙일보" ~ "야당지",

언론사 == "동앙일보" ~ "야당지",

언론사 == "국민일보" ~ "야당지",

언론사 == "문화일보" ~ "야당지",

언론사 == "한국경제" ~ "야당지",

언론사 == "경향신문" ~ "여당지",

TRUE ~ "여당지") ) %>%

separate(cat, sep = ">", into = c("cat", "cat2")) %>%

select(-cat2) %>%

mutate(catSoc = case_when( cat == "경제" ~ "경제면",
                           cat == "문화" ~ "경제면", 
                           TRUE ~ "비경제면") )

#주제별 갯수
yanolja_sub2 %>% count(cat, sort = T)
```

```{r}
#| label: 여기 어때 자료 정제
#| include: true
#| warning: false

hah_sub2 <- hah_sub %>%

distinct(제목, .keep_all = T) %>%

mutate(ID = factor(row_number())) %>%

mutate(week = week(ymd(일자))) %>%

unite(제목, 본문, col = "text", sep = " ") %>%

mutate(text = str_squish(text)) %>%

mutate(press = case_when(

언론사 == "조선일보" ~ "야당지",

언론사 == "중앙일보" ~ "야당지",

언론사 == "동앙일보" ~ "야당지",

언론사 == "국민일보" ~ "야당지",

언론사 == "문화일보" ~ "야당지",

언론사 == "한국경제" ~ "야당지",

언론사 == "경향신문" ~ "여당지",

TRUE ~ "여당지") ) %>%

separate(cat, sep = ">", into = c("cat", "cat2")) %>%

select(-cat2) %>%

mutate(catSoc = case_when(cat == "경제" ~ "경제면",
                          cat == "문화" ~ "경제면",
                          TRUE ~ "비경제면") )

#여기어때 주제별 갯수
hah_sub2 %>% count(cat, sort = T)
```

##### 3) 토큰화

```{r}
#| label: 야놀자 토큰화
#| include: false
#| warning: false

fullchar_v <- "ㆍ|ㅣ|‘|’|“|”|○|●|◎|◇|◆|□|■|△|▲|▽|▼|〓|◁|◀|▷|▶|♤|♠|♡|♥|♧|♣|⊙|◈|▣"


#야놀자 토큰화
yanolja_S <- yanolja_sub2 %>%

mutate(키워드 = str_remove_all(키워드, "[^(\\w+|\\d+|,)]")) %>%

mutate(키워드 = str_remove_all(키워드, fullchar_v)) %>%

unnest_tokens(word, 키워드, token = "regex", pattern = ",")

#토큰화 후 데이터 결합

yanolja_C <- yanolja_S %>%

group_by(ID) %>%

summarise(text2 = str_flatten(word, " ")) %>%

ungroup() %>%

inner_join(yanolja_sub2, by = "ID")
```

```{r}
#| label: 여기 어때 토큰화
#| include: false
#| warning: false

hah_S <- hah_sub2 %>%

mutate(키워드 = str_remove_all(키워드, "[^(\\w+|\\d+|,)]")) %>%

mutate(키워드 = str_remove_all(키워드, fullchar_v)) %>%

unnest_tokens(word, 키워드, token = "regex", pattern = ",")

#여기어때 데이터 결합

hah_C <- hah_S %>%

group_by(ID) %>%

summarise(text2 = str_flatten(word, " ")) %>%

ungroup() %>%

inner_join(hah_sub2, by = "ID")
```

##### 4) stm 말뭉치

```{r}
#| label: 야놀자 stm 말뭉치 & 객체 할당
#| include: true
#| warning: false

processed_yanol <- yanolja_C %>% 
  textProcessor(documents = yanolja_C$text2,
                metadata = .,
                wordLengths = c(2, Inf))

out_yanol <- prepDocuments(processed_yanol$documents,
                           processed_yanol$vocab,
                           processed_yanol$meta,
                           lower.thresh = 0)

summary(out_yanol)

# 모형구축을 위한 객체 저장
docs_yanol <- out_yanol$documents

vocab_yanol <- out_yanol$vocab

meta_yanol <- out_yanol$meta

```

```{r}
#| label: 여기 어때 stm 말뭉치 & 객체 할당
#| include: true
#| warning: false

processed_hah <- hah_C %>% textProcessor(documents = hah_C$text2,
                                         metadata = .,
                                         wordLengths = c(2, Inf))


out_hah <-prepDocuments(processed_hah$documents,
                        processed_hah$vocab,
                        processed_hah$meta,
                        lower.thresh = 0)

# 모형구축을 위한 객체 할당
summary(out_hah)

docs_hah <- out_hah$documents

vocab_hah <- out_hah$vocab

meta_hah <- out_hah$meta

```

##### 5) 공변인 분석

```{r}
#| label: 토픽 갯수 정하기
#| include: false
#| warning: false
#| eval: false
#주제 갯수
topicN <- c(3, 10)

storage_yanol <- searchK(docs_yanol, vocab_yanol, K = topicN)

storage_hah <- searchK(docs_hah, vocab_hah, K = topicN)
```

```{r}
#| label: 야놀자 주제모형(공변인) 분석
#| include: false
#| warning: false

#시스템 시간
t1 <- Sys.time()
t2 <- Sys.time()
#주제모형 구성
meta_fit_yanol <- stm(documents = docs_yanol,
                      vocab = vocab_yanol,
                      data = meta_yanol,
                      K = 10,
                      prevalence =~ press + s(week, 6), 
                      max.em.its = 75, 
                      verbose = F, 
                      init.type = "Spectral",
                      seed = 37)
```

```{r}
#| label: 여기 어때 주제모형(공변인) 분석
#| include: false
#| warning: false

plot(storage_hah)

meta_fit_hah <- stm(documents = docs_hah,
                    vocab = vocab_hah,
                    data = meta_hah,
                    K = 10,
                    prevalence =~ press + s(week, 6),
                    max.em.its = 75,
                    verbose = F,
                    init.type = "Spectral",
                    seed = 37)
```

##### 6) 주제 이름 짓기

```{r}
#| label: 야놀자 주제이름 짓기
#| include: true
#| warning: false

labelTopics(meta_fit_yanol)

#주제 이름 데이터 프레임에 저장
topic_name_yanol <- tibble(topic = 1:10,
                           name = c("1. 연휴, 여행",
                                    "2. 야놀자 클라우드 시스템",
                                    "3. 강원도 산불 피해자 지원",
                                    "4. 국정감사",
                                    "5. 온라인플렛폼공정화",
                                    "6. 인터파크 인수",
                                    "7. 유니콘 기업",
                                    "8. 블록체인 루니버스",
                                    "9. NFT",
                                    "10. 야놀자 송해 광고") )

#주제별 상위 7개 단어목록을 데이터 프레임에 저장
td_beta_yanol <- meta_fit_yanol %>% tidy(matrix = 'beta')

term_topic_name_yanol <- td_beta_yanol %>%

group_by(topic) %>%

slice_max(beta, n = 7) %>%

left_join(topic_name_yanol, by = "topic")
```

```{r}
#| label: 여기 어때주제이름 짓기
#| include: true
#| warning: false

labelTopics(meta_fit_hah)

#주제 이름 데이터 프레임에 저장
topic_name_hah <- tibble(topic = 1:10,
                         name = c("1. 여기어때 인수",
                                  "2. 경상북도 콜라보",
                                  "3. 불법크롤링 법정 문제",
                                  "4. 유니콘 기업",
                                  "5. 현대카드 콜라보",
                                  "6. 고객정보 대량유출",
                                  "7. 경기도 콜라보",
                                  "8. 여행 플랫폼",
                                  "9. 반려동물 여행",
                                  "10. 해외여행") )

#주제별 상위 7개 단어목록을 데이터 프레임에 저장
td_beta_hah <- meta_fit_hah %>% tidy(matrix = 'beta')

term_topic_name_hah <-
  
  td_beta_hah %>%
  
  group_by(topic) %>%
  
  slice_max(beta, n = 7) %>%
  
  left_join(topic_name_hah, by = "topic")
```

##### 7) 주제별 단어 분포표

```{r}
#| label: 야놀자 주제별 단어 분포표
#| include: true
#| warning: false

term_topic_name_yanol %>%
  ggplot(aes(x = beta,
             y = reorder_within(term, beta, name),
             fill = name)) +
  geom_col(show.legend = F) +
  
  facet_wrap(~name, scales = "free") +
  
  scale_y_reordered() + 
  
  labs(x = expression("단어 확률분포:"~beta), y = NULL,
       title = "주제별 단어 확률 분포",
       subtitle = "주제별로 다른 단어들로 군집") +
  
  theme(plot.title = element_text(size = 20))
```

```{r}
#| label: 여기 어때 주제별 단어 분포표
#| include: true
#| warning: false

term_topic_name_hah %>%
  
  ggplot(aes(x = beta,
             y = reorder_within(term, beta, name),
             fill = name)) +
  
  geom_col(show.legend = F) +
  
  facet_wrap(~name, scales = "free") +
  
  scale_y_reordered() +
  
  labs(x = expression("단어 확률분포:"~beta),
       y = NULL,
       title = "주제별 단어 확률 분포",
       subtitle = "주제별로 다른 단어들로 군집") +
  
  theme(plot.title = element_text(size = 20))
```

##### 8) 감마를 통한 주제 관련보도 상위 주제어

감마는 주제어의 문서 분포를 확인하기 위해 쓰지만 분석 자료로 사용하지 않고 감마의 평균값을 통하여 주제 관련 보도의 상위 주제어를 파악할 수 있다.

```{r}
#| label: 야놀자 감마 분석을 통한 상위 주제어
#| include: true
#| warning: false

#감마분석
td_gamma_yanol <- meta_fit_yanol %>% tidy(matrix = 'gamma')

#단어분포 자료를 통해 주제별 상위 7개 단어 선정
top_terms_yanol <-

td_beta_yanol %>%

group_by(topic) %>%

slice_max(beta, n = 7) %>%

select(topic, term) %>%

summarise(terms = str_flatten(term, collapse = ","))

top_terms_yanol
#주제별 감마 평균 계산
gamma_terms_yanol <-

td_gamma_yanol %>%

group_by(topic) %>%

summarise(gamma = mean(gamma)) %>%

left_join(top_terms_yanol, by = 'topic') %>% 

left_join(topic_name_yanol, by = 'topic')

gamma_terms_yanol
```

```{r}
#| label: 여기 어때 감마 분석을 통한 상위 주제어
#| include: true
#| warning: false

#감마분석
td_gamma_hah <- meta_fit_hah %>% tidy(matrix = 'gamma')

#단어분포 자료를 통해 주제별 상위 7개 단어 선정
top_terms_hah <-

td_beta_hah %>%

group_by(topic) %>%

slice_max(beta, n = 7) %>%

select(topic, term) %>%

summarise(terms = str_flatten(term, collapse = ","))

top_terms_hah

#주제별 감마 평균 계산
gamma_terms_hah <-

td_gamma_hah %>%

group_by(topic) %>%

summarise(gamma = mean(gamma)) %>%

left_join(top_terms_hah, by = 'topic') %>%

left_join(topic_name_hah, by = 'topic')

gamma_terms_hah
```

##### 9) 상위 주제어 그래프

```{r}
#| label: 야놀자 상위 주제어 그래프
#| include: true
#| warning: false

gamma_terms_yanol %>%
  
  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +
  
  geom_col(show.legend = F) +
  
  geom_text(aes(label = round(gamma, 2)),
            hjust = 1.15) + 
  
  geom_text(aes(label = terms),
            hjust = -0.05) + 
  
  scale_x_continuous(expand = c(0, 0), 
                     limit = c(0, .8)) + 
  
  labs(x = expression("문서 확률분포"~(gamma)), 
       y = NULL,
       title = "야놀자 관련 상위 주제어",
       subtitle = "주제별로 기여도가 높은 단어 중심") +
  
  theme(plot.title = element_text(size = 20))
```

```{r}
#| label: 여기 어때 상위 주제어 그래프
#| include: true
#| warning: false

gamma_terms_hah %>%

ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +

geom_col(show.legend = F) +

geom_text(aes(label = round(gamma, 2)), 
          hjust = 1.15) + 

geom_text(aes(label = terms),
          hjust = -0.05) + 

scale_x_continuous(expand = c(0, 0), 
                   limit = c(0, .8)) + 

labs(x = expression("문서 확률분포"~(gamma)),
     y = NULL,
     title = "여기 어때 관련 상위 주제어",
     subtitle = "주제별로 기여도가 높은 단어 중심") +
  
theme(plot.title = element_text(size = 20))
```
